> PipelineDB是一个用于在时序数据上持续执行SQL查询的高性能PostgreSQL插件。SQL查询的输出被持久化到普通的表中，可以像其它的表或视图一样进行查询。可以认为持续查询的结果是一个高吞吐量并且快速更新的物化视图。PipelineDB可以在某些任务场景下表现得十分优秀，若超出这个范畴，可能就会同其它数据处理系统一样面临一些问题。 pipelinedb运行原理 比如说我们用这个pipelinedb是要做一件事：我们要多维度实时统计一个大数据集，传统方法是把数据存到表中，查表统计，这个过程太慢了，于是你就需要用到pipelinedb了，它省去了你把数据存入表中的这个步骤，通过一个类似管道的东西把数据交给内存来直接计算，只保存统计结果，过程非常快，与各种统计需求是绝配。 官方文档：https://pipelinedb-doc-cn.readthedocs.io/zh_CN/latest/introduction.html
>

## PipelineDB的长处

* PipelineDB被设计用来在精简后的流式数据集上进行SQL查询。比如：概要和聚合；基于滑动时间窗口的性能计算；文本索引和过滤；空间信息过滤等。通过减少流数据的输入，PipelineDB可以显著地减少持久化到磁盘中的数据量，因为之后聚合后的结果被存储下来。原始数据（foreign table）一旦被需要它的持续查询读取后就会被销毁。
* 大多数写入到PipelineDB中的数据可以被视为 虚拟数据。数据虚拟化是PipelineDB设计的精髓，凭着这种设计，PipelineDB可以只占用较小的硬件资源实现高效的大数据量处理。
* PipelineDB的目标是消除许多数据传输中的ETL过程。原始数据流式写入PipelineDB，被已声明的流式查询实时地转换和提取，这使得它在将成型的输出加载到数据库前不必周期性地处理颗粒数据，前提是这些处理过程可以通过SQL定义。
* 在PipelineDB的设计理念中，实用性是第一要素，这也是我们将其包装为PostgreSQL插件的原因。所有数据存储和处理都交由PostgreSQL：一个极其稳定、成熟以及运用广泛的数据库。此外，PipelineDB兼容活跃的PostgreSQL生态中的所有工具。我们没有为PipelineDB设计特有的语法甚至是客户端，因为它可以很好地兼容任何基于PostgreSQL开发的库。

## PipelineDB的短板

* 鉴于流查询需要一些 先验知识，PipelineDB不是一个特定的数据仓库。流式查询的输出可能在特定方式下被访问，所有写入到PipelineDB中的原始数据都不会被持久化因为它们都会在读取后被销毁。此外，如果流式计算不能以SQL的形式表达，PipelineDB可能并不是一个合适的选择！

## 功能

### 流（foreign table）

流是一种允许客户端将时序数据写入 流视图 的抽象管道。流里面的一行数据（或者简单称作 event），与数据表中的行数据是很相似的，并且二者的写入也是完全一致的。然而，流和数据表的语义是完全不同的。

换言之，event 只会在被所有的 流视图 消费完之前“存在”于流中。即使这样，用户仍然不能直接从流中 SELECT 数据。流唯一的作用就是充当 流视图 的输入。

### 流视图

流视图（continuous view）是PipelineDB的基础概念抽象。流视图跟普通的数据库视图非常相似，但它是将流和表中的数据组合后作为输入并进行实时增量更新。 流数据一旦被流视图读取后就会被销毁，流数据不会存储在任何地方。只有诸如 SELECT * FROM that_view 查询返回的结果才会被持久化，也就是说，流视图可以被视为高吞吐量、实时的物化视图。

### 流转换

流转换可以在不存储时序的情况下对其进行实时转换。由于数据不存储数据，所以流转换不支持聚合操作。转换后的数据既可以作为另一个流的输入，也可以写入到外部数据存储中。

### 流聚合

PipelineDB最核心的追求之一就是 促进高性能的连续聚合，所以聚合函数毫无疑问是PipelineDB的核心功能。连续聚合在大多数通用场景是非常有用的，它使得PipelineDB中持久化的数据始终与写入的数据保持同步。它可以通过一定的硬件实现稳定和高吞度量的服务。 连续聚合是随着流视图新 event 的生成实时 增量更新的。对于如 count 和 sum 之类的简单聚合，我们很容易理解结果是如何增量更新的–将新值累加到已有结果上而已。 但对更加复杂的聚合而言，如 avg, stddev, percentile_cont 等，需要更优化的架构来支持高效的增量更新，PipelineDB在内部自动实现了这些复杂的逻辑。

### 流关联

流视图 的并非只靠select 流（foreign table） 产生，也可以通过将输入的时序数据和静态的PipelineDB数据表组合后得到，这可以用称作流-表关联的方式实现。

* 流-表关联
  * 流-表关联在 event到达时 将其与表中匹配的行数据组合。换言之，如果在表数据在 event 被读取后才被插入，即使是匹配的，也不会对流视图产生影响。新数据只会在 event被读取时 产生。即使流-表关联中的表被清空了，流视图中的数据也不会变化。
  * 流-流关联 目前不支持流之间的关联，这个功能可能会出现在将来的版本中。 ***译者注： 2019年5月1日，PipelineDB公司宣布加入Confluent（Kafka的公司），官方版将会停留在1.0.0，详情见 官方报道(https://www.pipelinedb.com/blog/pipelinedb-is-joining-confluent)。***

***pipelinedb作者给出建议：1、使用confluent的ksql（商业软件）代替pipelinedb 2、如果还是钟爱pg系列，timescaledb 扩展是一个不错的选择***

### 滑动窗口

由于 流视图 是实时增量更新的，PipelineDB可以在更新流视图结果集时考虑当前时间。WHERE 子句中包含与 当前时间 相关信息的查询被称作 滑动窗口查询。滑动的 WHERE 子句过滤或接收到的 event 集合是随时间持续变化的。

### 内置函数

我们努力保证PipelineDB同PostgreSQL的10.1+和11.0+版本保持完全兼容。因此，所有 PostgreSQL内置函数 都可以直接在PipelineDB中使用。

### PipelineDB特有函数

具体查看：https://pipelinedb-doc-cn.readthedocs.io/zh_CN/latest/builtin.html#id4